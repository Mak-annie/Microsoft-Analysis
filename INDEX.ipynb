{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MICROSOFT MOVIE ANALYSIS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.BUSINESS UNDERSTANDING"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    A.INTRODUCTION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When choosing the kinds of films to make, resource limitations must be taken into consideration. Understanding the available resources can help you determine the size and extent of the movie studio's production capabilities, including the budget, talent pool, and technological infrastructure. Microsoft will be able to set standards for success and gauge the studio's performance in the market by defining the major success measures, such as box office revenues, profitability, audience ratings, and critical acclaim. \n",
    "\n",
    "Additionally, it is crucial to take into account the wants and requirements of the many parties involved, particularly the head of Microsoft's film division. It will be possible to make sure that the conclusions and insights drawn from the analysis are suited to their demands for making decisions by comprehending their vision, goals, and particular requirements.\n",
    "\n",
    "Microsoft can successfully investigate the kinds of movies that are now successful at the box office by developing a thorough understanding of the commercial context. The conclusions drawn from this project will offer the head of the movie studio implementable suggestions that will direct their choices regarding the ideal film production approach. This includes choosing a genre that appeals to the target demographic, allocating resources wisely, and matching the movies' branding to Microsoft. In the end, these insights will help Microsoft produce hit movies and forge a significant foothold in the film business.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    B.PROBLEM STATEMENT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Microsoft's inexperience in the movie-making industry is a major barrier to the success of their recently launched movie studio. The current challenge is to identify the traits and categories of movies that have enjoyed significant box office success. The idea is to provide the head of Microsoft's movie studio with the knowledge needed to choose the kinds of movies to make, increasing the likelihood of success."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    C.MAIN OBJECTIVE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform exploratory data analysis in order to learn more about the kinds of movies that are currently doing well at the box office"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    D.SPECIFIC OBJECTIVES"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Conduct exploratory data analysis to find patterns, trends, and connections between audience preferences, box office success, and popular genres."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Draw conclusions that can be put into practice from the data analysis, highlighting the categories of movies that are connecting with audiences and doing well at the box office."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Deliver a thorough presentation that includes a summary of the data analysis's findings, conclusions, and suggestions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.READING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>studio</th>\n",
       "      <th>domestic_gross</th>\n",
       "      <th>foreign_gross</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story 3</td>\n",
       "      <td>BV</td>\n",
       "      <td>415000000.0</td>\n",
       "      <td>652000000</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alice in Wonderland (2010)</td>\n",
       "      <td>BV</td>\n",
       "      <td>334200000.0</td>\n",
       "      <td>691300000</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Deathly Hallows Part 1</td>\n",
       "      <td>WB</td>\n",
       "      <td>296000000.0</td>\n",
       "      <td>664300000</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Inception</td>\n",
       "      <td>WB</td>\n",
       "      <td>292600000.0</td>\n",
       "      <td>535700000</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shrek Forever After</td>\n",
       "      <td>P/DW</td>\n",
       "      <td>238700000.0</td>\n",
       "      <td>513900000</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         title studio  domestic_gross  \\\n",
       "0                                  Toy Story 3     BV     415000000.0   \n",
       "1                   Alice in Wonderland (2010)     BV     334200000.0   \n",
       "2  Harry Potter and the Deathly Hallows Part 1     WB     296000000.0   \n",
       "3                                    Inception     WB     292600000.0   \n",
       "4                          Shrek Forever After   P/DW     238700000.0   \n",
       "\n",
       "  foreign_gross  year  \n",
       "0     652000000  2010  \n",
       "1     691300000  2010  \n",
       "2     664300000  2010  \n",
       "3     535700000  2010  \n",
       "4     513900000  2010  "
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading data on movie gross\n",
    "bom_data = pd.read_csv('Datasets/bom.movie_gross.csv.gz')\n",
    "bom_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>release_date</th>\n",
       "      <th>movie</th>\n",
       "      <th>production_budget</th>\n",
       "      <th>domestic_gross</th>\n",
       "      <th>worldwide_gross</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Dec 18, 2009</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>$425,000,000</td>\n",
       "      <td>$760,507,625</td>\n",
       "      <td>$2,776,345,279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>May 20, 2011</td>\n",
       "      <td>Pirates of the Caribbean: On Stranger Tides</td>\n",
       "      <td>$410,600,000</td>\n",
       "      <td>$241,063,875</td>\n",
       "      <td>$1,045,663,875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Jun 7, 2019</td>\n",
       "      <td>Dark Phoenix</td>\n",
       "      <td>$350,000,000</td>\n",
       "      <td>$42,762,350</td>\n",
       "      <td>$149,762,350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>May 1, 2015</td>\n",
       "      <td>Avengers: Age of Ultron</td>\n",
       "      <td>$330,600,000</td>\n",
       "      <td>$459,005,868</td>\n",
       "      <td>$1,403,013,963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Dec 15, 2017</td>\n",
       "      <td>Star Wars Ep. VIII: The Last Jedi</td>\n",
       "      <td>$317,000,000</td>\n",
       "      <td>$620,181,382</td>\n",
       "      <td>$1,316,721,747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  release_date                                        movie  \\\n",
       "0   1  Dec 18, 2009                                       Avatar   \n",
       "1   2  May 20, 2011  Pirates of the Caribbean: On Stranger Tides   \n",
       "2   3   Jun 7, 2019                                 Dark Phoenix   \n",
       "3   4   May 1, 2015                      Avengers: Age of Ultron   \n",
       "4   5  Dec 15, 2017            Star Wars Ep. VIII: The Last Jedi   \n",
       "\n",
       "  production_budget domestic_gross worldwide_gross  \n",
       "0      $425,000,000   $760,507,625  $2,776,345,279  \n",
       "1      $410,600,000   $241,063,875  $1,045,663,875  \n",
       "2      $350,000,000    $42,762,350    $149,762,350  \n",
       "3      $330,600,000   $459,005,868  $1,403,013,963  \n",
       "4      $317,000,000   $620,181,382  $1,316,721,747  "
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading data on budgets\n",
    "budgets_data = pd.read_csv('Datasets/tn.movie_budgets.csv.gz')\n",
    "budgets_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>primary_title</th>\n",
       "      <th>original_title</th>\n",
       "      <th>start_year</th>\n",
       "      <th>runtime_minutes</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0063540</td>\n",
       "      <td>Sunghursh</td>\n",
       "      <td>Sunghursh</td>\n",
       "      <td>2013</td>\n",
       "      <td>175.0</td>\n",
       "      <td>Action,Crime,Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0066787</td>\n",
       "      <td>One Day Before the Rainy Season</td>\n",
       "      <td>Ashad Ka Ek Din</td>\n",
       "      <td>2019</td>\n",
       "      <td>114.0</td>\n",
       "      <td>Biography,Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0069049</td>\n",
       "      <td>The Other Side of the Wind</td>\n",
       "      <td>The Other Side of the Wind</td>\n",
       "      <td>2018</td>\n",
       "      <td>122.0</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0069204</td>\n",
       "      <td>Sabse Bada Sukh</td>\n",
       "      <td>Sabse Bada Sukh</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Comedy,Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0100275</td>\n",
       "      <td>The Wandering Soap Opera</td>\n",
       "      <td>La Telenovela Errante</td>\n",
       "      <td>2017</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Comedy,Drama,Fantasy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tconst                    primary_title              original_title  \\\n",
       "0  tt0063540                        Sunghursh                   Sunghursh   \n",
       "1  tt0066787  One Day Before the Rainy Season             Ashad Ka Ek Din   \n",
       "2  tt0069049       The Other Side of the Wind  The Other Side of the Wind   \n",
       "3  tt0069204                  Sabse Bada Sukh             Sabse Bada Sukh   \n",
       "4  tt0100275         The Wandering Soap Opera       La Telenovela Errante   \n",
       "\n",
       "   start_year  runtime_minutes                genres  \n",
       "0        2013            175.0    Action,Crime,Drama  \n",
       "1        2019            114.0       Biography,Drama  \n",
       "2        2018            122.0                 Drama  \n",
       "3        2018              NaN          Comedy,Drama  \n",
       "4        2017             80.0  Comedy,Drama,Fantasy  "
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading data on titles basics\n",
    "title_data = pd.read_csv('Datasets/imdb.title.basics.csv.gz')\n",
    "title_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>averagerating</th>\n",
       "      <th>numvotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt10356526</td>\n",
       "      <td>8.3</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt10384606</td>\n",
       "      <td>8.9</td>\n",
       "      <td>559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt1042974</td>\n",
       "      <td>6.4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt1043726</td>\n",
       "      <td>4.2</td>\n",
       "      <td>50352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt1060240</td>\n",
       "      <td>6.5</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tconst  averagerating  numvotes\n",
       "0  tt10356526            8.3        31\n",
       "1  tt10384606            8.9       559\n",
       "2   tt1042974            6.4        20\n",
       "3   tt1043726            4.2     50352\n",
       "4   tt1060240            6.5        21"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading data on ratings\n",
    "ratings_data = pd.read_csv('Datasets/imdb.title.ratings.csv.gz')\n",
    "ratings_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>genre_ids</th>\n",
       "      <th>id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_date</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[12, 14, 10751]</td>\n",
       "      <td>12444</td>\n",
       "      <td>en</td>\n",
       "      <td>Harry Potter and the Deathly Hallows: Part 1</td>\n",
       "      <td>33.533</td>\n",
       "      <td>2010-11-19</td>\n",
       "      <td>Harry Potter and the Deathly Hallows: Part 1</td>\n",
       "      <td>7.7</td>\n",
       "      <td>10788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[14, 12, 16, 10751]</td>\n",
       "      <td>10191</td>\n",
       "      <td>en</td>\n",
       "      <td>How to Train Your Dragon</td>\n",
       "      <td>28.734</td>\n",
       "      <td>2010-03-26</td>\n",
       "      <td>How to Train Your Dragon</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[12, 28, 878]</td>\n",
       "      <td>10138</td>\n",
       "      <td>en</td>\n",
       "      <td>Iron Man 2</td>\n",
       "      <td>28.515</td>\n",
       "      <td>2010-05-07</td>\n",
       "      <td>Iron Man 2</td>\n",
       "      <td>6.8</td>\n",
       "      <td>12368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[16, 35, 10751]</td>\n",
       "      <td>862</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>28.005</td>\n",
       "      <td>1995-11-22</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>7.9</td>\n",
       "      <td>10174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[28, 878, 12]</td>\n",
       "      <td>27205</td>\n",
       "      <td>en</td>\n",
       "      <td>Inception</td>\n",
       "      <td>27.920</td>\n",
       "      <td>2010-07-16</td>\n",
       "      <td>Inception</td>\n",
       "      <td>8.3</td>\n",
       "      <td>22186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            genre_ids     id original_language  \\\n",
       "0           0      [12, 14, 10751]  12444                en   \n",
       "1           1  [14, 12, 16, 10751]  10191                en   \n",
       "2           2        [12, 28, 878]  10138                en   \n",
       "3           3      [16, 35, 10751]    862                en   \n",
       "4           4        [28, 878, 12]  27205                en   \n",
       "\n",
       "                                 original_title  popularity release_date  \\\n",
       "0  Harry Potter and the Deathly Hallows: Part 1      33.533   2010-11-19   \n",
       "1                      How to Train Your Dragon      28.734   2010-03-26   \n",
       "2                                    Iron Man 2      28.515   2010-05-07   \n",
       "3                                     Toy Story      28.005   1995-11-22   \n",
       "4                                     Inception      27.920   2010-07-16   \n",
       "\n",
       "                                          title  vote_average  vote_count  \n",
       "0  Harry Potter and the Deathly Hallows: Part 1           7.7       10788  \n",
       "1                      How to Train Your Dragon           7.7        7610  \n",
       "2                                    Iron Man 2           6.8       12368  \n",
       "3                                     Toy Story           7.9       10174  \n",
       "4                                     Inception           8.3       22186  "
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading data on movies\n",
    "movies_data = pd.read_csv('Datasets/tmdb.movies.csv.gz')\n",
    "movies_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.DATA CLEANING"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    4.1.UNIQUE IDENTIFIERS $ DUPLICATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in column 'year':\n",
      "[2010 2011 2012 2013 2014 2015 2016 2017 2018]\n",
      "Number of unique values in column 'year': 9\n"
     ]
    }
   ],
   "source": [
    "#identify the unique identifiers on the bom dataset\n",
    "columns_to_check = ['title','studio','domestic_gross','foreign_gross','year']\n",
    "\n",
    "for column in columns_to_check:\n",
    "    unique_values = bom_data[column].unique()\n",
    "    num_unique_values = bom_data[column].nunique()\n",
    "print(f\"Unique values in column '{column}':\")\n",
    "print(unique_values)\n",
    "print(f\"Number of unique values in column '{column}': {num_unique_values}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 duplicates found in column 'title'.\n",
      "This constitutes 0.029525% of the column.\n",
      "3129 duplicates found in column 'studio'.\n",
      "This constitutes 92.382640% of the column.\n",
      "1589 duplicates found in column 'domestic_gross'.\n",
      "This constitutes 46.914674% of the column.\n",
      "2182 duplicates found in column 'foreign_gross'.\n",
      "This constitutes 64.422793% of the column.\n",
      "3378 duplicates found in column 'year'.\n",
      "This constitutes 99.734278% of the column.\n"
     ]
    }
   ],
   "source": [
    "def check_column_duplicates(bom_data):\n",
    "    for column in bom_data.columns:\n",
    "        duplicates_count = bom_data[column].duplicated().sum()\n",
    "        duplicates_percentage = (duplicates_count / len(bom_data)) * 100\n",
    "\n",
    "        if duplicates_count == 0:\n",
    "            print(f\"No duplicates found in column '{column}'.\")\n",
    "        else:\n",
    "            print(f\"{duplicates_count} duplicates found in column '{column}'.\")\n",
    "            print(f\"This constitutes {duplicates_percentage:2f}% of the column.\")\n",
    "\n",
    "check_column_duplicates(bom_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in column 'worldwide_gross':\n",
      "['$2,776,345,279' '$1,045,663,875' '$149,762,350' ... '$240,495' '$1,338'\n",
      " '$181,041']\n",
      "Number of unique values in column 'worldwide_gross': 5356\n"
     ]
    }
   ],
   "source": [
    "#identify the unique  identifier in the budgets dataset\n",
    "columns_to_check = ['id','release_date','movie','production_budget','domestic_gross','worldwide_gross']\n",
    "\n",
    "for column in columns_to_check:\n",
    "    unique_values = budgets_data[column].unique()\n",
    "    num_unique_values = budgets_data[column].nunique()\n",
    "print(f\"Unique values in column '{column}':\")\n",
    "print(unique_values)\n",
    "print(f\"Number of unique values in column '{column}': {num_unique_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5682 duplicates found in column 'id'.\n",
      "This constitutes 98.270495% of the column.\n",
      "3364 duplicates found in column 'release_date'.\n",
      "This constitutes 58.180560% of the column.\n",
      "84 duplicates found in column 'movie'.\n",
      "This constitutes 1.452785% of the column.\n",
      "5273 duplicates found in column 'production_budget'.\n",
      "This constitutes 91.196818% of the column.\n",
      "618 duplicates found in column 'domestic_gross'.\n",
      "This constitutes 10.688343% of the column.\n",
      "426 duplicates found in column 'worldwide_gross'.\n",
      "This constitutes 7.367693% of the column.\n"
     ]
    }
   ],
   "source": [
    "#check for duplicates in the budgets dataset\n",
    "def check_column_duplicates(data):\n",
    "    for column in data.columns:\n",
    "        duplicates_count = data[column].duplicated().sum()\n",
    "        duplicates_percentage = (duplicates_count / len(data)) * 100\n",
    "\n",
    "        if duplicates_count == 0:\n",
    "            print(f\"No duplicates found in column '{column}'.\")\n",
    "        else:\n",
    "            print(f\"{duplicates_count} duplicates found in column '{column}'.\")\n",
    "            print(f\"This constitutes {duplicates_percentage:2f}% of the column.\")\n",
    "\n",
    "check_column_duplicates(budgets_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in column 'genres':\n",
      "['Action,Crime,Drama' 'Biography,Drama' 'Drama' ...\n",
      " 'Music,Musical,Reality-TV' 'Animation,Crime' 'Adventure,History,War']\n",
      "Number of unique values in column 'genres': 1085\n"
     ]
    }
   ],
   "source": [
    "#identify the unique  identifier in the titles dataset\n",
    "columns_to_check = ['tconst','primary_title','original_title','start_year','runtime_minutes','genres']\n",
    "\n",
    "for column in columns_to_check:\n",
    "    unique_values = title_data[column].unique()\n",
    "    num_unique_values = title_data[column].nunique()\n",
    "print(f\"Unique values in column '{column}':\")\n",
    "print(unique_values)\n",
    "print(f\"Number of unique values in column '{column}': {num_unique_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicates found in column 'tconst'.\n",
      "10073 duplicates found in column 'primary_title'.\n",
      "This constitutes 6.892517% of the column.\n",
      "8370 duplicates found in column 'original_title'.\n",
      "This constitutes 5.727228% of the column.\n",
      "146125 duplicates found in column 'start_year'.\n",
      "This constitutes 99.986999% of the column.\n",
      "145776 duplicates found in column 'runtime_minutes'.\n",
      "This constitutes 99.748194% of the column.\n",
      "145058 duplicates found in column 'genres'.\n",
      "This constitutes 99.256897% of the column.\n"
     ]
    }
   ],
   "source": [
    "#check for duplicates in the titles dataset\n",
    "def check_column_duplicates(data):\n",
    "    for column in data.columns:\n",
    "        duplicates_count = data[column].duplicated().sum()\n",
    "        duplicates_percentage = (duplicates_count / len(data)) * 100\n",
    "\n",
    "        if duplicates_count == 0:\n",
    "            print(f\"No duplicates found in column '{column}'.\")\n",
    "        else:\n",
    "            print(f\"{duplicates_count} duplicates found in column '{column}'.\")\n",
    "            print(f\"This constitutes {duplicates_percentage:2f}% of the column.\")\n",
    "\n",
    "check_column_duplicates(title_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in column 'vote_average':\n",
      "[ 7.7  6.8  7.9  8.3  6.1  7.4  7.2  7.5  6.6  6.   6.7  4.5  7.3  8.1\n",
      "  6.3  4.6  5.7  5.9  8.2  6.2  6.4  7.6  6.5  7.1  5.6  5.3  7.   5.8\n",
      "  4.9  5.1  5.5  6.9  5.4  7.8  4.7  4.1  4.8  3.2  8.   3.7  5.2  2.7\n",
      "  4.4  5.   2.9  2.   4.   4.2  3.9  4.3  3.5  3.8  3.6  3.4  3.3  3.1\n",
      "  3.   2.5  2.6 10.   2.2  1.7  2.8  2.3  1.6  1.8  2.4  1.5  8.6  1.9\n",
      "  9.   8.7  0.5  1.   8.4  2.1  8.8  1.3  9.5  8.5  9.8  0.   8.9  9.3\n",
      "  9.4  9.2  0.8  1.2  1.4  9.1  9.7]\n",
      "Number of unique values in column 'vote_average': 91\n"
     ]
    }
   ],
   "source": [
    "#identify the unique  identifier in the movies dataset\n",
    "columns_to_check = ['Unnamed: 0','genre_ids','id','original_language','original_title','popularity','title', 'release_date','vote_count','vote_average']\n",
    "\n",
    "for column in columns_to_check:\n",
    "    unique_values = movies_data[column].unique()\n",
    "    num_unique_values = movies_data[column].nunique()\n",
    "print(f\"Unique values in column '{column}':\")\n",
    "print(unique_values)\n",
    "print(f\"Number of unique values in column '{column}': {num_unique_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicates found in column 'Unnamed: 0'.\n",
      "24040 duplicates found in column 'genre_ids'.\n",
      "This constitutes 90.658823% of the column.\n",
      "1020 duplicates found in column 'id'.\n",
      "This constitutes 3.846589% of the column.\n",
      "26441 duplicates found in column 'original_language'.\n",
      "This constitutes 99.713391% of the column.\n",
      "1682 duplicates found in column 'original_title'.\n",
      "This constitutes 6.343101% of the column.\n",
      "19092 duplicates found in column 'popularity'.\n",
      "This constitutes 71.999095% of the column.\n",
      "23084 duplicates found in column 'release_date'.\n",
      "This constitutes 87.053588% of the column.\n",
      "1829 duplicates found in column 'title'.\n",
      "This constitutes 6.897462% of the column.\n",
      "26426 duplicates found in column 'vote_average'.\n",
      "This constitutes 99.656824% of the column.\n",
      "24824 duplicates found in column 'vote_count'.\n",
      "This constitutes 93.615417% of the column.\n"
     ]
    }
   ],
   "source": [
    "#check for duplicates in the movie dataset\n",
    "def check_column_duplicates(data):\n",
    "    for column in data.columns:\n",
    "        duplicates_count = data[column].duplicated().sum()\n",
    "        duplicates_percentage = (duplicates_count / len(data)) * 100\n",
    "\n",
    "        if duplicates_count == 0:\n",
    "            print(f\"No duplicates found in column '{column}'.\")\n",
    "        else:\n",
    "            print(f\"{duplicates_count} duplicates found in column '{column}'.\")\n",
    "            print(f\"This constitutes {duplicates_percentage:2f}% of the column.\")\n",
    "\n",
    "check_column_duplicates(movies_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    4.2. CHECKING FOR MISSING VALUES IN THE DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title                0\n",
      "studio               5\n",
      "domestic_gross      28\n",
      "foreign_gross     1350\n",
      "year                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#bom dataset\n",
    "missing_values = bom_data.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has missing values in the columns:studio, domestic_gross and foreign_gross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                   0\n",
      "release_date         0\n",
      "movie                0\n",
      "production_budget    0\n",
      "domestic_gross       0\n",
      "worldwide_gross      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#budgets dataset\n",
    "missing_values = budgets_data.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tconst                 0\n",
      "primary_title          0\n",
      "original_title        21\n",
      "start_year             0\n",
      "runtime_minutes    31739\n",
      "genres              5408\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#titles dataset\n",
    "missing_values = title_data.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has missing values in the columns: original_title, runtime_minutes and genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tconst           0\n",
      "averagerating    0\n",
      "numvotes         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#ratings dataset\n",
    "missing_values = ratings_data.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0           0\n",
      "genre_ids            0\n",
      "id                   0\n",
      "original_language    0\n",
      "original_title       0\n",
      "popularity           0\n",
      "release_date         0\n",
      "title                0\n",
      "vote_average         0\n",
      "vote_count           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#movies dataset\n",
    "missing_values = movies_data.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has no missing values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        4.3. DROPPING COLUMNS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only a few features and rows from the various datasets that were gathered are important to the procedure. As a result, in this stage, the features from each dataset that were not necessary were removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of column with duplicates\n",
    "\"\"\"\n",
    "The title column was dropped as it is not possible \n",
    "for one movie to have different titles\n",
    "\"\"\"\n",
    "#drop column with duplicates\n",
    "bom_data.drop_duplicates(subset='title', keep='first', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3386, 5)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bom_data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains 3386 rows and 5 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           tconst                                primary_title  start_year\n",
      "0       tt0063540                                    Sunghursh        2013\n",
      "1       tt0066787              One Day Before the Rainy Season        2019\n",
      "2       tt0069049                   The Other Side of the Wind        2018\n",
      "3       tt0069204                              Sabse Bada Sukh        2018\n",
      "4       tt0100275                     The Wandering Soap Opera        2017\n",
      "...           ...                                          ...         ...\n",
      "146139  tt9916538                          Kuambil Lagi Hatiku        2019\n",
      "146140  tt9916622  Rodolpho Teóphilo - O Legado de um Pioneiro        2015\n",
      "146141  tt9916706                              Dankyavar Danka        2013\n",
      "146142  tt9916730                                       6 Gunn        2017\n",
      "146143  tt9916754               Chico Albuquerque - Revelações        2013\n",
      "\n",
      "[146144 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#list of columns with missing values\n",
    "columns_with_missing_values = ['original_title','runtime_minutes', 'genres']\n",
    "#drop columns with missing values\n",
    "title_data= title_data.drop(columns_with_missing_values, axis=1)\n",
    "print(title_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146144, 3)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains 146144 rows and 3 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.drop of            id original_language                                original_title  \\\n",
      "0       12444                en  Harry Potter and the Deathly Hallows: Part 1   \n",
      "1       10191                en                      How to Train Your Dragon   \n",
      "2       10138                en                                    Iron Man 2   \n",
      "3         862                en                                     Toy Story   \n",
      "4       27205                en                                     Inception   \n",
      "...       ...               ...                                           ...   \n",
      "26512  488143                en                         Laboratory Conditions   \n",
      "26513  485975                en                               _EXHIBIT_84xxx_   \n",
      "26514  381231                en                                  The Last One   \n",
      "26515  366854                en                                  Trailer Made   \n",
      "26516  309885                en                                    The Church   \n",
      "\n",
      "       popularity release_date                                         title  \\\n",
      "0          33.533   2010-11-19  Harry Potter and the Deathly Hallows: Part 1   \n",
      "1          28.734   2010-03-26                      How to Train Your Dragon   \n",
      "2          28.515   2010-05-07                                    Iron Man 2   \n",
      "3          28.005   1995-11-22                                     Toy Story   \n",
      "4          27.920   2010-07-16                                     Inception   \n",
      "...           ...          ...                                           ...   \n",
      "26512       0.600   2018-10-13                         Laboratory Conditions   \n",
      "26513       0.600   2018-05-01                               _EXHIBIT_84xxx_   \n",
      "26514       0.600   2018-10-01                                  The Last One   \n",
      "26515       0.600   2018-06-22                                  Trailer Made   \n",
      "26516       0.600   2018-10-05                                    The Church   \n",
      "\n",
      "       vote_average  vote_count  \n",
      "0               7.7       10788  \n",
      "1               7.7        7610  \n",
      "2               6.8       12368  \n",
      "3               7.9       10174  \n",
      "4               8.3       22186  \n",
      "...             ...         ...  \n",
      "26512           0.0           1  \n",
      "26513           0.0           1  \n",
      "26514           0.0           1  \n",
      "26515           0.0           1  \n",
      "26516           0.0           1  \n",
      "\n",
      "[26517 rows x 8 columns]>\n"
     ]
    }
   ],
   "source": [
    "#drop the unnamed column from the movies dataset\n",
    "movies_data.drop(['Unnamed: 0', 'genre_ids'], axis=1, inplace=True)\n",
    "print(movies_data.drop)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    4.4.FORMATTING DATATYPES"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the budgets data, convert the 'production_budget', 'domestic_gross' and 'worldwide_gross' columns to numeric data type and convert to float type. then convert the 'release_date' column to a datetime data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id  release_date                                        movie  \\\n",
      "0      1  Dec 18, 2009                                       Avatar   \n",
      "1      2  May 20, 2011  Pirates of the Caribbean: On Stranger Tides   \n",
      "2      3   Jun 7, 2019                                 Dark Phoenix   \n",
      "3      4   May 1, 2015                      Avengers: Age of Ultron   \n",
      "4      5  Dec 15, 2017            Star Wars Ep. VIII: The Last Jedi   \n",
      "...   ..           ...                                          ...   \n",
      "5777  78  Dec 31, 2018                                       Red 11   \n",
      "5778  79   Apr 2, 1999                                    Following   \n",
      "5779  80  Jul 13, 2005                Return to the Land of Wonders   \n",
      "5780  81  Sep 29, 2015                         A Plague So Pleasant   \n",
      "5781  82   Aug 5, 2005                            My Date With Drew   \n",
      "\n",
      "      production_budget  domestic_gross  worldwide_gross  \n",
      "0           425000000.0     760507625.0     2.776345e+09  \n",
      "1           410600000.0     241063875.0     1.045664e+09  \n",
      "2           350000000.0      42762350.0     1.497624e+08  \n",
      "3           330600000.0     459005868.0     1.403014e+09  \n",
      "4           317000000.0     620181382.0     1.316722e+09  \n",
      "...                 ...             ...              ...  \n",
      "5777             7000.0             0.0     0.000000e+00  \n",
      "5778             6000.0         48482.0     2.404950e+05  \n",
      "5779             5000.0          1338.0     1.338000e+03  \n",
      "5780             1400.0             0.0     0.000000e+00  \n",
      "5781             1100.0        181041.0     1.810410e+05  \n",
      "\n",
      "[5782 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#convert the datatypes to float and datetime\n",
    "columns=['production_budget', 'domestic_gross','worldwide_gross']\n",
    "for a in columns:\n",
    "    budgets_data[a] = budgets_data[a].str.replace(r'\\D', '',regex=True).astype(float)\n",
    "   \n",
    "print(budgets_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id release_date                                        movie  \\\n",
      "0      1   2009-12-18                                       Avatar   \n",
      "1      2   2011-05-20  Pirates of the Caribbean: On Stranger Tides   \n",
      "2      3   2019-06-07                                 Dark Phoenix   \n",
      "3      4   2015-05-01                      Avengers: Age of Ultron   \n",
      "4      5   2017-12-15            Star Wars Ep. VIII: The Last Jedi   \n",
      "...   ..          ...                                          ...   \n",
      "5777  78   2018-12-31                                       Red 11   \n",
      "5778  79   1999-04-02                                    Following   \n",
      "5779  80   2005-07-13                Return to the Land of Wonders   \n",
      "5780  81   2015-09-29                         A Plague So Pleasant   \n",
      "5781  82   2005-08-05                            My Date With Drew   \n",
      "\n",
      "      production_budget  domestic_gross  worldwide_gross  \n",
      "0           425000000.0     760507625.0     2.776345e+09  \n",
      "1           410600000.0     241063875.0     1.045664e+09  \n",
      "2           350000000.0      42762350.0     1.497624e+08  \n",
      "3           330600000.0     459005868.0     1.403014e+09  \n",
      "4           317000000.0     620181382.0     1.316722e+09  \n",
      "...                 ...             ...              ...  \n",
      "5777             7000.0             0.0     0.000000e+00  \n",
      "5778             6000.0         48482.0     2.404950e+05  \n",
      "5779             5000.0          1338.0     1.338000e+03  \n",
      "5780             1400.0             0.0     0.000000e+00  \n",
      "5781             1100.0        181041.0     1.810410e+05  \n",
      "\n",
      "[5782 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "budgets_data['release_date'] = pd.to_datetime(budgets_data['release_date'])\n",
    "print(budgets_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            title      studio  domestic_gross  \\\n",
      "0                                     Toy Story 3          BV     415000000.0   \n",
      "1                      Alice in Wonderland (2010)          BV     334200000.0   \n",
      "2     Harry Potter and the Deathly Hallows Part 1          WB     296000000.0   \n",
      "3                                       Inception          WB     292600000.0   \n",
      "4                             Shrek Forever After        P/DW     238700000.0   \n",
      "...                                           ...         ...             ...   \n",
      "3382                                    The Quake       Magn.          6200.0   \n",
      "3383                  Edward II (2018 re-release)          FM          4800.0   \n",
      "3384                                     El Pacto        Sony          2500.0   \n",
      "3385                                     The Swan  Synergetic          2400.0   \n",
      "3386                            An Actor Prepares       Grav.          1700.0   \n",
      "\n",
      "      foreign_gross                          year  \n",
      "0       652000000.0 1970-01-01 00:00:00.000002010  \n",
      "1       691300000.0 1970-01-01 00:00:00.000002010  \n",
      "2       664300000.0 1970-01-01 00:00:00.000002010  \n",
      "3       535700000.0 1970-01-01 00:00:00.000002010  \n",
      "4       513900000.0 1970-01-01 00:00:00.000002010  \n",
      "...             ...                           ...  \n",
      "3382            NaN 1970-01-01 00:00:00.000002018  \n",
      "3383            NaN 1970-01-01 00:00:00.000002018  \n",
      "3384            NaN 1970-01-01 00:00:00.000002018  \n",
      "3385            NaN 1970-01-01 00:00:00.000002018  \n",
      "3386            NaN 1970-01-01 00:00:00.000002018  \n",
      "\n",
      "[3386 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#convert the datatypes\n",
    "bom_data['foreign_gross'] = bom_data['foreign_gross'].str.replace(',', '').astype(float)\n",
    "bom_data['foreign_gross'] = bom_data['foreign_gross'].astype(float)\n",
    "bom_data['year'] = pd.to_datetime(bom_data['year'])\n",
    "print(bom_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3386, 5)"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bom_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "bom_data.rename(columns={'year': 'release_date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_data.drop_duplicates(subset='id', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25497, 8)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3386, 5)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bom_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146144, 3)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    5.MERGING DATASETS\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets were merged in order to provide a better analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first datasets to be merged are budgets and movie dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename the column in order to be able to merge the common column\n",
    "df.rename(columns={'movie': 'title'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename the vote_average to ratings\n",
    "movies_data.rename(columns={'vote_average':'average_rating'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_data.rename(columns={'primary_title':'title'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['title', 'production_budget', 'worldwide_gross', 'release_date'], dtype='object')\n",
      "Index(['id', 'original_language', 'original_title', 'popularity',\n",
      "       'release_date', 'title', 'average_rating', 'vote_count'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "print(movies_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id original_language  \\\n",
      "0       12444                en   \n",
      "1       10191                en   \n",
      "2       10138                en   \n",
      "3       27205                en   \n",
      "4       32657                en   \n",
      "...       ...               ...   \n",
      "22396  381231                en   \n",
      "22397  381231                en   \n",
      "22398  381231                en   \n",
      "22399  366854                en   \n",
      "22400  309885                en   \n",
      "\n",
      "                                          original_title  popularity  \\\n",
      "0           Harry Potter and the Deathly Hallows: Part 1      33.533   \n",
      "1                               How to Train Your Dragon      28.734   \n",
      "2                                             Iron Man 2      28.515   \n",
      "3                                              Inception      27.920   \n",
      "4      Percy Jackson & the Olympians: The Lightning T...      26.691   \n",
      "...                                                  ...         ...   \n",
      "22396                                       The Last One       0.600   \n",
      "22397                                       The Last One       0.600   \n",
      "22398                                       The Last One       0.600   \n",
      "22399                                       Trailer Made       0.600   \n",
      "22400                                         The Church       0.600   \n",
      "\n",
      "      release_date                                              title  \\\n",
      "0       2010-11-19       Harry Potter and the Deathly Hallows: Part 1   \n",
      "1       2010-03-26                           How to Train Your Dragon   \n",
      "2       2010-05-07                                         Iron Man 2   \n",
      "3       2010-07-16                                          Inception   \n",
      "4       2010-02-11  Percy Jackson & the Olympians: The Lightning T...   \n",
      "...            ...                                                ...   \n",
      "22396   2018-10-01                                       The Last One   \n",
      "22397   2018-10-01                                       The Last One   \n",
      "22398   2018-10-01                                       The Last One   \n",
      "22399   2018-06-22                                       Trailer Made   \n",
      "22400   2018-10-05                                         The Church   \n",
      "\n",
      "       average_rating  vote_count     tconst  start_year  \n",
      "0                 7.7       10788  tt0926084        2010  \n",
      "1                 7.7        7610  tt0892769        2010  \n",
      "2                 6.8       12368  tt1228705        2010  \n",
      "3                 8.3       22186  tt1375666        2010  \n",
      "4                 6.1        4229  tt0814255        2010  \n",
      "...               ...         ...        ...         ...  \n",
      "22396             0.0           1  tt2962488        2014  \n",
      "22397             0.0           1  tt3118968        2018  \n",
      "22398             0.0           1  tt6261158        2017  \n",
      "22399             0.0           1  tt3377456        2016  \n",
      "22400             0.0           1  tt2482856        2018  \n",
      "\n",
      "[22401 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "merged_data = pd.merge(movies_data, title_data, on='title', how='inner')\n",
    "print(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22401, 10)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id original_language              original_title  popularity  \\\n",
      "0      10191                en    How to Train Your Dragon      28.734   \n",
      "1      10138                en                  Iron Man 2      28.515   \n",
      "2      27205                en                   Inception      27.920   \n",
      "3      10193                en                 Toy Story 3      24.445   \n",
      "4      20352                en               Despicable Me      23.673   \n",
      "...      ...               ...                         ...         ...   \n",
      "3411  473262                it                  Nico, 1988       3.789   \n",
      "3412  465871                en             Maria by Callas       3.184   \n",
      "3413  332718                en  Bilal: A New Breed of Hero       2.707   \n",
      "3414  498919                es        La Boda de Valentina       2.550   \n",
      "3415  551634                zh                       你好，之华       0.600   \n",
      "\n",
      "     release_date_x                       title  average_rating  vote_count  \\\n",
      "0        2010-03-26    How to Train Your Dragon             7.7        7610   \n",
      "1        2010-05-07                  Iron Man 2             6.8       12368   \n",
      "2        2010-07-16                   Inception             8.3       22186   \n",
      "3        2010-06-17                 Toy Story 3             7.7        8340   \n",
      "4        2010-07-09               Despicable Me             7.2       10057   \n",
      "...             ...                         ...             ...         ...   \n",
      "3411     2018-07-04                  Nico, 1988             7.3          40   \n",
      "3412     2018-11-02             Maria by Callas             7.6          11   \n",
      "3413     2018-02-02  Bilal: A New Breed of Hero             6.8          54   \n",
      "3414     2018-02-09        La Boda de Valentina             6.3           7   \n",
      "3415     2018-11-09                 Last Letter             6.0           1   \n",
      "\n",
      "         tconst  start_year studio  domestic_gross  foreign_gross  \\\n",
      "0     tt0892769        2010   P/DW     217600000.0    277300000.0   \n",
      "1     tt1228705        2010   Par.     312400000.0    311500000.0   \n",
      "2     tt1375666        2010     WB     292600000.0    535700000.0   \n",
      "3     tt0435761        2010     BV     415000000.0    652000000.0   \n",
      "4     tt1323594        2010   Uni.     251500000.0    291600000.0   \n",
      "...         ...         ...    ...             ...            ...   \n",
      "3411  tt7186092        2017  Magn.         73300.0            NaN   \n",
      "3412  tt7364566        2017    SPC       1300000.0            NaN   \n",
      "3413  tt3576728        2015     VE        491000.0      1700000.0   \n",
      "3414  tt4823538        2018    PNT       2800000.0            NaN   \n",
      "3415  tt9078374        2018     CL        181000.0            NaN   \n",
      "\n",
      "                    release_date_y  \n",
      "0    1970-01-01 00:00:00.000002010  \n",
      "1    1970-01-01 00:00:00.000002010  \n",
      "2    1970-01-01 00:00:00.000002010  \n",
      "3    1970-01-01 00:00:00.000002010  \n",
      "4    1970-01-01 00:00:00.000002010  \n",
      "...                            ...  \n",
      "3411 1970-01-01 00:00:00.000002018  \n",
      "3412 1970-01-01 00:00:00.000002018  \n",
      "3413 1970-01-01 00:00:00.000002018  \n",
      "3414 1970-01-01 00:00:00.000002018  \n",
      "3415 1970-01-01 00:00:00.000002018  \n",
      "\n",
      "[3416 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "merged_data = pd.merge(merged_data, bom_data, on='title', how='inner')\n",
    "print(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.rename(columns={'release_date_x':'release_date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id original_language              original_title  popularity  \\\n",
      "0      10191                en    How to Train Your Dragon      28.734   \n",
      "1      10138                en                  Iron Man 2      28.515   \n",
      "2      27205                en                   Inception      27.920   \n",
      "3      10193                en                 Toy Story 3      24.445   \n",
      "4      20352                en               Despicable Me      23.673   \n",
      "...      ...               ...                         ...         ...   \n",
      "3411  473262                it                  Nico, 1988       3.789   \n",
      "3412  465871                en             Maria by Callas       3.184   \n",
      "3413  332718                en  Bilal: A New Breed of Hero       2.707   \n",
      "3414  498919                es        La Boda de Valentina       2.550   \n",
      "3415  551634                zh                       你好，之华       0.600   \n",
      "\n",
      "     release_date                       title  average_rating  vote_count  \\\n",
      "0      2010-03-26    How to Train Your Dragon             7.7        7610   \n",
      "1      2010-05-07                  Iron Man 2             6.8       12368   \n",
      "2      2010-07-16                   Inception             8.3       22186   \n",
      "3      2010-06-17                 Toy Story 3             7.7        8340   \n",
      "4      2010-07-09               Despicable Me             7.2       10057   \n",
      "...           ...                         ...             ...         ...   \n",
      "3411   2018-07-04                  Nico, 1988             7.3          40   \n",
      "3412   2018-11-02             Maria by Callas             7.6          11   \n",
      "3413   2018-02-02  Bilal: A New Breed of Hero             6.8          54   \n",
      "3414   2018-02-09        La Boda de Valentina             6.3           7   \n",
      "3415   2018-11-09                 Last Letter             6.0           1   \n",
      "\n",
      "         tconst  start_year studio  domestic_gross  foreign_gross  \\\n",
      "0     tt0892769        2010   P/DW     217600000.0    277300000.0   \n",
      "1     tt1228705        2010   Par.     312400000.0    311500000.0   \n",
      "2     tt1375666        2010     WB     292600000.0    535700000.0   \n",
      "3     tt0435761        2010     BV     415000000.0    652000000.0   \n",
      "4     tt1323594        2010   Uni.     251500000.0    291600000.0   \n",
      "...         ...         ...    ...             ...            ...   \n",
      "3411  tt7186092        2017  Magn.         73300.0            NaN   \n",
      "3412  tt7364566        2017    SPC       1300000.0            NaN   \n",
      "3413  tt3576728        2015     VE        491000.0      1700000.0   \n",
      "3414  tt4823538        2018    PNT       2800000.0            NaN   \n",
      "3415  tt9078374        2018     CL        181000.0            NaN   \n",
      "\n",
      "                    release_date_y  \n",
      "0    1970-01-01 00:00:00.000002010  \n",
      "1    1970-01-01 00:00:00.000002010  \n",
      "2    1970-01-01 00:00:00.000002010  \n",
      "3    1970-01-01 00:00:00.000002010  \n",
      "4    1970-01-01 00:00:00.000002010  \n",
      "...                            ...  \n",
      "3411 1970-01-01 00:00:00.000002018  \n",
      "3412 1970-01-01 00:00:00.000002018  \n",
      "3413 1970-01-01 00:00:00.000002018  \n",
      "3414 1970-01-01 00:00:00.000002018  \n",
      "3415 1970-01-01 00:00:00.000002018  \n",
      "\n",
      "[3416 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "print(merged_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. ANALYSIS OF DATA.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA VISUALIZATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        movie  production_budget  \\\n",
      "0                                      Avatar        425000000.0   \n",
      "3                      Avengers:Age of Ultron        330600000.0   \n",
      "4             Stars Wars Ep.VII:The Last Jedi        317000000.0   \n",
      "1  Pirates of the Caribbean:On Stranger Tides        410600000.0   \n",
      "2                                Dark Phoenix        350000000.0   \n",
      "\n",
      "   worldwide_gross release_date        profit       roi  \n",
      "0     2.776345e+09   2022-05-15  2.351345e+09  5.532576  \n",
      "3     1.403010e+09   2022-03-10  1.072410e+09  3.243829  \n",
      "4     1.316711e+09   2021-11-24  9.997110e+08  3.153662  \n",
      "1     1.045664e+09   2021-08-20  6.350640e+08  1.546673  \n",
      "2     1.487624e+08   2023-01-05 -2.012376e+08 -0.574965  \n"
     ]
    }
   ],
   "source": [
    "#analyze the relationship between spending and profits at the box office\n",
    "#calculate profit by subtracting production project from worldwide gross\n",
    "df['profit'] = df['worldwide_gross'] - df['production_budget']\n",
    "#calculate the return on investment (ROI)by dividing profit by production budget\n",
    "df['roi'] = df['profit'] / df['production_budget']\n",
    "#sort the movies by ROI in descending order\n",
    "sorted_movies= df.sort_values('roi', ascending=False)\n",
    "#display the top 10 movies with highest ROI\n",
    "top_movies_roi = sorted_movies.head(10)\n",
    "print(top_movies_roi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
